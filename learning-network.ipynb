{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import imp\n",
    "import network\n",
    "import mynet\n",
    "imp.reload(network)\n",
    "imp.reload(mynet)\n",
    "\n",
    "def printValues(listVals):\n",
    "   for i in range(len(listVals)):\n",
    "        print(listVals[i])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original weights: (list of <class 'numpy.ndarray'>)\n",
      "<class 'numpy.ndarray'>\n",
      "[[0.52292845 0.67581768 0.64377182 0.43170139]\n",
      " [0.9359769  0.56116772 0.37938211 0.99719719]]\n",
      "\n",
      "[[0.17844689 0.2052944 ]\n",
      " [0.05782458 0.71445456]\n",
      " [0.03332703 0.61467988]]\n",
      "\n",
      "shape of net.weights[0]: (2, 4)\n",
      "\n",
      "new weights:\n",
      "[[0.1 0.2 0.3 0.4]\n",
      " [1.1 1.2 1.3 1.4]]\n",
      "\n",
      "[[ 0.5 -0.5]\n",
      " [ 0.6 -1. ]\n",
      " [ 0.7 -2. ]]\n",
      "\n",
      "new biases: (list of <class 'numpy.ndarray'>)\n",
      "<class 'numpy.ndarray'>\n",
      "[[1.]\n",
      " [1.]]\n",
      "\n",
      "[[2.]\n",
      " [2.]\n",
      " [2.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sizes = [4,2,3]\n",
    "net = network.Network(sizes)\n",
    "\n",
    "print(\"original weights: (list of \" + str(type(net.weights[0])) + \")\")\n",
    "print(type(net.weights[0]))\n",
    "printValues(net.weights)\n",
    "print(\"shape of net.weights[0]: \" + str(net.weights[0].shape))\n",
    "\n",
    "# manually set weights for connections between layers 0 and 1\n",
    "net.weights[0]=np.array([[0.1, 0.2, 0.3, 0.4], [1.1,1.2,1.3,1.4]])\n",
    "# same for layers 1 and 2\n",
    "net.weights[1]=np.array([[0.5, -0.5], [0.6, -1], [0.7, -2]])\n",
    "\n",
    "# manually set biases as well\n",
    "net.biases[0] = np.array([[1.0], [1.0]])\n",
    "net.biases[1] = np.array([[2.0], [2.0], [2.0]])\n",
    "\n",
    "print(\"\\nnew weights:\")\n",
    "printValues(net.weights)\n",
    "\n",
    "print(\"new biases: (list of \" + str(type(net.biases[0])) + \")\")\n",
    "print(type(net.biases[0]))\n",
    "printValues(net.biases)\n",
    "\n",
    "# make a copy of this network using my class instead\n",
    "mine = mynet.Network(sizes)\n",
    "mine.weights = copy.deepcopy(net.weights)\n",
    "mine.biases = copy.deepcopy(net.biases)\n",
    "mine.sizes = copy.deepcopy(net.sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing forward pass evaluation...\n",
      "testing backprop function...\n",
      "testing updateMiniBatch function...\n",
      "\n",
      "final outputs on training data:\n",
      "[[0.32718759]\n",
      " [0.32832133]\n",
      " [0.36315287]]\n",
      "[[0.03581287]\n",
      " [0.03283559]\n",
      " [0.92782885]]\n",
      "\n",
      "finsihed all tests!\n"
     ]
    }
   ],
   "source": [
    "# test my code vs network.py\n",
    "\n",
    "def train(x, y):\n",
    "    rate = 0.1\n",
    "    mine_b, mine_w = mine.backprop(x, y)\n",
    "    mine.biases = [b - rate * db for b, db in zip(mine.biases, mine_b)]\n",
    "    mine.weights = [w - rate * dw for w, dw in zip(mine.weights, mine_w)]\n",
    "\n",
    "# training data lists\n",
    "X = []\n",
    "Y = []\n",
    "X.append(np.array([[1], [2], [3], [4]]))\n",
    "Y.append(np.array([[0.0], [1.0], [0.0]]))\n",
    "\n",
    "X.append(np.array([[-1], [-4], [-99], [0.3]]))\n",
    "Y.append(np.array([[0.333], [0.333], [0.333]]))\n",
    "\n",
    "X.append(np.array([[7.0], [4], [9], [6]]))\n",
    "Y.append(np.array([[0], [0], [1.0]]))\n",
    "\n",
    "print(\"testing forward pass evaluation...\")\n",
    "assert(np.allclose(net.feedforward(X[0]), mine.evaluate(X[0])))\n",
    "\n",
    "print(\"testing backprop function...\")\n",
    "nabla_b, nabla_w = net.backprop(X[0], Y[0])\n",
    "mine_b, mine_w = mine.backprop(X[0], Y[0])\n",
    "# https://stackoverflow.com/a/30773738\n",
    "assert(all([np.allclose(nb, mb) for nb, mb in zip(nabla_b, mine_b)]))\n",
    "assert(all([np.allclose(nw, mw) for nw, mw in zip(nabla_w, mine_w)]))\n",
    "\n",
    "print(\"testing updateMiniBatch function...\")\n",
    "# test with a batch size of 1\n",
    "net.update_mini_batch([(X[index], Y[index])], 0.25)\n",
    "mine.updateMiniBatch([(X[index], Y[index])], 0.25)\n",
    "assert(all([np.allclose(b, mb) for b, mb in zip(net.weights, mine.weights)]))\n",
    "assert(all([np.allclose(w, mw) for w, mw in zip(net.biases, mine.biases)]))\n",
    "\n",
    "X = X[1:3]\n",
    "Y = Y[1:3]\n",
    "\n",
    "batch = [(x,y) for x,y in zip(X,Y)]\n",
    "iterations = 1000\n",
    "for i in range(iterations):\n",
    "    index = i % len(X)\n",
    "    net.update_mini_batch(batch, 0.25)\n",
    "    mine.updateMiniBatch(batch, 0.25)\n",
    "    \n",
    "# test weights and biases were updated to same values\n",
    "assert(all([np.allclose(b, mb) for b, mb in zip(net.weights, mine.weights)]))\n",
    "assert(all([np.allclose(w, mw) for w, mw in zip(net.biases, mine.biases)]))\n",
    "\n",
    "print(\"\\nfinal outputs on training data:\")\n",
    "# now test:\n",
    "for x,y in zip(X, Y):\n",
    "    assert(np.allclose(net.feedforward(x), mine.evaluate(x)))\n",
    "    print(mine.evaluate(x))\n",
    "    \n",
    "print(\"\\nfinsihed all tests!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
